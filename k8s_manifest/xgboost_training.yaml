apiVersion: kubeflow.org/v1
kind: MPIJob
spec:
  slotsPerWorker: 1
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          containers:
            - name: launcher
              image: nhutp/xgboost:latest
              env:
                - name: LEARNING_RATE
                  value: "${trialParameters.GEN_LEARNING_RATE}"
                - name: MAX_DEPTH
                  value: "${trialParameters.GEN_MAX_DEPTH}"
                - name: NUM_ROUND
                  value: "${trialParameters.GEN_NUM_ROUND}"
                - name: TRIAL_NAME
                  value: "${trialParameters.TRIAL_NAME}"

                # ðŸ”½ MLflow env variables ðŸ”½
                - name: MLFLOW_TRACKING_URI
                  value: "http://mlflow.kubeflow.svc.cluster.local:5000"  # <== Replace with your MLflow server URL
                - name: MLFLOW_EXPERIMENT_NAME
                  value: "xgboost-katib"
                # Optional: for basic auth (if your MLflow uses it)
                # - name: MLFLOW_TRACKING_USERNAME
                #   valueFrom:
                #     secretKeyRef:
                #       name: mlflow-secret
                #       key: username
                # - name: MLFLOW_TRACKING_PASSWORD
                #   valueFrom:
                #     secretKeyRef:
                #       name: mlflow-secret
                #       key: password

              command: ["/bin/bash", "-c"]
              args:
                - |
                  echo "[Katib Launcher] Waiting for workers...";
                  echo $TRIAL_NAME;
                  echo "$TRIAL_NAME-worker-0.kubeflow.svc.cluster.local"
                  echo "$LEARNING_RATE";
                  echo "$MAX_DEPTH";
                  sleep 10;
                  mpirun -n 2 --allow-run-as-root \
                    -bind-to none -map-by slot \
                    -x DMLC_NUM_WORKER=2 \
                    -x DMLC_TRACKER_URI="$TRIAL_NAME-worker-0.kubeflow.svc.cluster.local" \
                    -x DMLC_TRACKER_PORT=9091 \
                    -x DMLC_ROLE=worker \
                    -x OMPI_COMM_WORLD_RANK \
                    python train_xgboost.py

    Worker:
      replicas: 2
      template:
        spec:
          containers:
            - name: worker
              image: nhutp/xgboost:latest

